# International Data Week 2016 - Meeting Notes and Links

*International Data Week in September 2016 brought together three events, SciDataCon, the International Data Forum, and the Research Data Alliance 8th  plenary. Joe Hand from the Dat team attended the conference and collected his notes and interesting links here. Check out [Joe's reflection post](http://LINKME) from International Data Week too.*

## SciDataCon2016

SciDataCon featured sessions with 5-10 quick lightning talk each on a common theme. Notes from some of the more interesting sessions are below.

### [Session on Sustainable Business Models for Data Repositories](http://www.scidatacon.org/2016/sessions/45/)

These two sessions covered the costs, budgets, and revenue streams for various data repositories. There are many different pricing structures. Details on these can be found in the witness statements in the session link above. 

Repositories are using a mix of subscriptions (paid by libraries, insitutions, researchers), pay to download (to get specific datasets), or pay to deposit (pay to upload to the repository), and external funding (government, private). 

While each pricing model has its own strengths and downsides, it was clear the loser is the academic institutions, libraries, and researchers. Several library managers and researchers expressed concern that soon they will be unable to keep up financially with the number of data repository subscriptions they need to get data, similar to the issues being faced with journal subscriptions. Additionally, as more data becomes replicated in several places, it becomes unclear which repositories should be subscribed to.

From the perspective of Dat, the costs were the most interesting part. For many of the data repositories hosting and bandwidth covers 1/4th to 1/3rd of the costs. We hope that Dat will be able to better distribute or reduce a lot of those costs.

Repositories that offer *active* dataset curation also had a high cost for the curators, a relatively new profession, at around 1/3 of the total costs.

Finally, the last big chunk of spending was on software development and general research and development. This is not surprising, software is expensive. But it was surprising to see how many repositories were replicating the same costs developing similar software.

### TODO: other sessions I have notes from

## International Data Forum

### TODO

## Research Data Alliance (RDA) 8th Plenary

The RDA plenary had sessions for working groups, interest groups, and birds of a feather groups (informal, single-time events). Each of these sessions involved some presentation with plenty of time for discussion.

Research Data Alliance is a collection of academics, librarians, and other groups involved with research data. RDA has [good primer](https://rd-alliance.org/rda-newcomers-some-notes) on their organization structure. They meet regularly with a focus on interest groups and working groups. Working groups and interest groups continue to communicate throughout the year to form recommendations (working groups) or help inform discussion throughout RDA (interest groups).

### Session Notes

Notes from specific sessions collected below.

#### [Long Tail Data IG Meeting](https://rd-alliance.org/ig-long-tail-research-data-rda-8th-plenary-meeting)

* The [interest group of long tail data](https://rd-alliance.org/groups/long-tail-research-data-ig.html) is very relevant to Dat. They are [drafting these recommendations](https://docs.google.com/document/d/1TL2VbuIs8mHDT4MZyK3jqkdSP7cL9O7GbMbapu_9CNQ/edit).
* Amazon succeeded by providing access to the long tail of books. There is a huge gap is services/infrastructure for the long tail of data. This long tail is from individual researchers. Generally small data (>1GB). **90% of researchers keep data on local, lab, or institution servers/backups, not in data repositories.** 
* Most data isn't highly structured or doesn't have standardized metadata. But this is where a lot of the innovation comes from. Newer research fields, newer types of data, etc. These data will be impossible to put in many data repositories.
* "Important to show immediate value upon deposit [to a data repository]". 
* "[Data] needs to link to other resources". 
* "Data that doesn't lead to publication is the data that currently gets lost".
* [Big data, little data, no data](https://mitpress.mit.edu/big-data-little-data-no-data) - Book that may be of interest.
* Orphan data are the bigger problem, data that don't have a home.
* Libraries will provide for a key partner in managing and publishing this type of data.
* Metadata is important but need to strike balance between ease of use and standardization/discovery.

#### [Joint meeting of IG Preservation e-Infrastructure, IG Reproducibility: Knowledge Preservation Tools for Researchers](https://rd-alliance.org/rda-8th-plenary-joint-meeting-ig-preservation-e-infrastructure%C2%A0ig-reproducibility)

* How can we foster relationships in overlap between researcher and archivist? Bridge the gap between researcher with data and preservation needs. What tools are necessary to make this easier?
* **If a researcher wants to preserve data, they have to share it.** Non-trivial thing and can be daunting for researchers.
* If a researcher can make your workflows work on remote computers, they can preserve it for reproducible execution.
* **"No generic preservation tool exists"** (speaker assertion). Must be some level of commonality to preserve all science & research inputs (data, software, workflow, etc.). Capture should complete for reproducibility. 
* "Not tool will be adopted unless there is economic incentive (enlightened self-interest)"
* What is meant by reproducibility? Trying to get the same answer or independently implement the same methodology to see what answer if given. There are always people reproducing others' work, usually students, postdocs. No way to publish or credit them. We know they are happening But not what happens or who is doing them. We only hear about them when they differ significantly from the original result. 
* **Major risk using these tools (data repository, online reproducibility software, etc.) is what happens if a tool get deprecated, loses funding, etc.**

#### [Data Versioning BOF](https://rd-alliance.org/data-versioning-rda-8th-plenary-bof-meeting)

* [Identification of Reproducible Subsets for Data Citation,
Sharing and Re-Use Guidelines](https://www.rd-alliance.org/system/files/documents/TCDL-RDA-Guidelines_160411.pdf)
* How to do data versioning with colocation with petascale computers and cloud intensive computing?
* Not just an issue for big data, also small datasets.
* query subsetting data is important; spatial queries useful
* "it is hard for a researcher to cite the exact data extract used to support investigation". particularly with subsets or dynamic queries
* **Battle over who assigns the DOI/PID for dataset and subsets of data**. If data is of value, institution or repository owner is prepared to store it. But who mints the DOI?
* Lots of different perspectives on how to version and what is relevant. 
* What happens when storage is full and old versions need to be discarded? How to achieve proper persistence/archiving while managing space?

### RDA Working Groups and Interest Groups of Interest

There are lots of interesting working groups and interest groups in the Research Data Alliance. A few already have specific recommendations out, that may overlap with Dat:

* [Data citation working group recommendation](https://rd-alliance.org/group/data-citation-wg/outcomes/data-citation-recommendation.html)
* [Persistent Identifiers recommendation](https://rd-alliance.org/system/files/PIT%20final%20report.pdf)
* (more soon)

There are also many RDA working groups and interest groups that are in progress, i.e. formalizing their recommendations, that overlap with Dat:

* Research data provenance
* Repository platforms for research data
* Publishing data working group
* E-infrastructure
* Persistent Identifiers (PID) interest group
* National data services
* **Long tail is research data** (very relevant)
* Data description interoperability
* Research data repository interoperability
* Publishing data services

---

## Links of Interest Collected Throughout IDW

* [DataFAIRport](http://www.datafairport.org/) - Their vision is to join and support existing communities that try to realize and enable a situation where valuable scientific data is ‘FAIR’ in the sense of being Findable, Accessible, Interoperable and Reusable.
* [Scholix](http://www.scholix.org/) (elsevier) - high level interoperability framework for exchanging information about the links between scholarly literature and data. It aims to build an open information ecosystem to understand systematically what data underpins literature and what literature references data.
* **[Maslow hierarchy for research data](https://www.elsevier.com/connect/10-aspects-of-highly-effective-research-data)** - This is really interesting to think about. Seems like Dat is focused more on the bottom two sections.
* [Preserving data at risk](http://www.codata.org/task-groups/data-at-risk)

### Data Repositories of Interest

* There are [over 1,500 data repositories](http://www.re3data.org/) according to the re3data registry.
* [BioCaddie](https://biocaddie.org/) - A *meta* data repository ( collection of other data repositories). Recently released, they've done a ton of work on ingesting other data repositories. 
* [ProteinDataBank](http://www.rcsb.org/pdb/home/home.do) - 555GB of protein data. Specifically, there may be good opportunity for Dat to test large scale sharing and versioning. They currently have [this versioning scheme](http://www.rcsb.org/pdb/static.do?p=download/ftp/index.html) and [downloads over FTP](http://www.wwpdb.org/download/downloads).
* [datasearch - elsevier](https://datasearch.elsevier.com/) -  *meta* data repository 
* [share - open science framework](https://share.osf.io/) -  *meta* data repository 

## Metadata, Standards, Interoperability

* Tons of discussion across many groups of metadata, standards, and interoperability. This is a huge problem. There are many many (way more than I though) specific domain or more generalized data repositories. Some of these have common metadata (usually in domain specific case) but lots of data repositories have their own and rely on translations to/from other metadata formats in order to improve interoperability.
* Metadata is great in that it allows you to do things like improved visualization, validation, discovery. 
* Data curation (making sure a repository has only high-quality data) relies very heavily on metadata.
* Many groups trying to figure out the perfect metadata so they can improve data discovery and curation. Some are supposed to be more general repositories and some domain specific.
